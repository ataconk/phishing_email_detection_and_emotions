{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61558bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os, gc, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2d978bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mails_fold = '/Users/atacank/Downloads/maildir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2de9b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mails_dir_raw = []\n",
    "all_mails_content = []\n",
    "saka = []\n",
    "for root, subdirectories, files in os.walk(mails_fold):\n",
    "    # for subdirectory in subdirectories:\n",
    "    #    print(os.path.join(root, subdirectory))\n",
    "    for file in files:\n",
    "        # print(os.path.join(root, file))\n",
    "        try:\n",
    "            with open(os.path.join(root, file), 'r') as f2:\n",
    "                data = f2.read()\n",
    "                all_mails_content.append(data)\n",
    "            all_mails_dir_raw.append(os.path.join(root, file))\n",
    "            saka.append([os.path.join(root, file), data])\n",
    "            \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d0c1d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "cropped_mails_dir = random.sample(all_mails_dir_raw, 3974)\n",
    "cropped_mails_content = random.sample(all_mails_content, 3974)\n",
    "cropped_data = random.sample(saka, 3974)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db76877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6d90f665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3974"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a26649b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron_df = pd.DataFrame(cropped_data, columns = ['file', 'message'])\n",
    "df = enron_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "531af795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Message-ID: <17334447.1075857585446.JavaMail.evans@thyme>\\nDate: Thu, 16 Nov 2000 09:30:00 -0800 (PST)\\nFrom: msagel@home.com\\nTo: jarnold@enron.com\\nSubject: Status\\nMime-Version: 1.0\\nContent-Type: text/plain; charset=ANSI_X3.4-1968\\nContent-Transfer-Encoding: 7bit\\nX-From: \"Mark Sagel\" <msagel@home.com>\\nX-To: \"John Arnold\" <jarnold@enron.com>\\nX-cc: \\nX-bcc: \\nX-Folder: \\\\John_Arnold_Dec2000\\\\Notes Folders\\\\Notes inbox\\nX-Origin: Arnold-J\\nX-FileName: Jarnold.nsf\\n\\nJohn:\\n?\\nI\\'m not really sure what happened between us.? I was  under the impression \\nafter my visit to Houston that we were about to enter into  a trial agreement \\nfor my advisory work.? Somehow,?this never  occurred.? Did I say or do \\nsomething wrong to screw this  up???\\n?\\nI don\\'t know if you\\'ve blown this whole thing off, but I still  hope you are \\ninterested in trying?to create an arrangement.? As a  courtesy, here is my \\nreport from this past weekend.? If you are no longer  interested in my work, \\nplease tell me so.??Best wishes,\\n?\\nMark Sagel\\nPsytech Analytics\\n(410)308-0245? \\n - energy2000-1112.doc'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron_df['message'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25736d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_part(i):\n",
    "    \"\"\"split infomation part out\"\"\"\n",
    "    return i.split('\\n\\n', 1)[0]\n",
    "def content_part(i):\n",
    "    \"\"\"split content part out\"\"\"\n",
    "    return i.split('\\n\\n', 1)[1]\n",
    "\n",
    "df['pre_info'] = df.message.map(info_part)\n",
    "df['content'] = df.message.map(content_part)\n",
    "df['test_true'] = True\n",
    "\n",
    "words2split = ['Message-ID: ', 'Date: ', 'From: ', 'To: ', 'Subject: ', 'Cc: ', 'Mime-Version: ', 'Content-Type: ',\n",
    "               'Content-Transfer-Encoding: ', 'Bcc: ', 'X-From: ', 'X-To: ', 'X-cc: ', 'X-bcc: ', 'X-Folder: ', 'X-Origin: ',\n",
    "               'X-FileName: ']\n",
    "features_naming = [i[:-2] for i in words2split]\n",
    "split_condition = '|'.join(words2split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99ef6c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some emails' subject confuse the string-spliting function, so I make a little change\n",
    "def duplicated_info(i):\n",
    "    return i.replace(' Date: ', ' Date- ').replace(' Subject: ', ' Subject2: ').replace(' To: ',\n",
    "                    ' To- ').replace(' (Subject: ', ' (Subject- ')\n",
    "df['pre_info'] = df['pre_info'].map(duplicated_info)\n",
    "\n",
    "# let's check how many categories are there in these emails\n",
    "def num_part(i):\n",
    "    return len(re.split(split_condition, i))\n",
    "df['num_info'] = df['pre_info'].map(num_part)\n",
    "\n",
    "# around 20k emails do not have the 'To: ' category, so I add one\n",
    "def add_to(i):\n",
    "    return i.replace('\\nSubject: ', '\\nTo: \\nSubject: ')\n",
    "temp_condition = (df['num_info'] == 17) | (df['num_info'] == 15)\n",
    "df.loc[temp_condition, 'pre_info'] = df.loc[temp_condition, 'pre_info'].map(add_to)\n",
    "\n",
    "\n",
    "# similar way to deal with the \"Cc:\" and \"Bcc:\" categories\n",
    "temp_condition = (df['num_info'] == 16) | (df['num_info'] == 15)\n",
    "def add_bcc(i):\n",
    "    return i.replace('\\nX-From: ', '\\nBcc: \\nX-From: ')\n",
    "df.loc[temp_condition, 'pre_info'] = df.loc[temp_condition, 'pre_info'].map(add_bcc)\n",
    "def add_cc(i):\n",
    "    return i.replace('\\nMime-Version: ', '\\nCc: \\nMime-Version: ')\n",
    "df.loc[temp_condition, 'pre_info'] = df.loc[temp_condition, 'pre_info'].map(add_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "82e1572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clearnsh(i):\n",
    "    return i.replace('\\n', ' ')\n",
    "\n",
    "def cleartsh(i):\n",
    "    return i.replace('\\t', ' ')\n",
    "df['content'] = df['content'].map(clearnsh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1af40e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18    5000\n",
       "Name: num_info, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['num_info'] = df['pre_info'].map(num_part)\n",
    "df['num_info'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "52caeae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remove = df.loc[df['num_info'] != 18].copy()\n",
    "df = df.loc[df['num_info'] == 18].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d20caacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "global feature_idx\n",
    "def info_split(i):\n",
    "    ## split the i th part out and remove \\n for the feature\n",
    "    return re.split(split_condition, i)[feature_idx+1][:-2]\n",
    "def info_split_last(i):\n",
    "    ## no need to remove \\n for last category -- X-FileName\n",
    "    return re.split(split_condition, i)[feature_idx+1]\n",
    "for feature_idx in range(len(words2split)):\n",
    "    if feature_idx != len(words2split) - 1:\n",
    "        df[features_naming[feature_idx]] = df['pre_info'].map(info_split)\n",
    "    else:\n",
    "        df[features_naming[feature_idx]] = df['pre_info'].map(info_split_last) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "892cc5cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7bi                4854\n",
       "quoted-printabl     146\n",
       "Name: Content-Transfer-Encoding, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Content-Transfer-Encoding'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c40dbe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remove2 = df.loc[df['Content-Transfer-Encoding'] == 'text/plain; charset=us-asci']\n",
    "df = df.loc[df['Content-Transfer-Encoding'] != 'text/plain; charset=us-asci']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2786bfed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5       >Sender: articles-email@ms1.lga2.nytimes.com\\n...\n",
       "17      I had Devon put together a resume for you to g...\n",
       "29      (See attached file: g051401.pdf)\\n\\n\\n________...\n",
       "35      Greetings from Amazon.com.\\n\\nTo finish resett...\n",
       "36      Reminder - Reminder - Reminder\\n\\nRemember tha...\n",
       "                              ...                        \n",
       "4978    ---------------------- Forwarded by Rosalee Fl...\n",
       "4981    The following servers will be coming down, ple...\n",
       "4988    This meeting has been postponed today at 12 p....\n",
       "4991    John:\\n\\nListed below are two companies who ca...\n",
       "4994    You know, when the accountant does the spreads...\n",
       "Name: content, Length: 853, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[\"content\"].str.contains(\"-------------\"), \"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43e1615c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_other_content(i):\n",
    "    \"\"\"split other forms of contents out\"\"\"\n",
    "    return i.split('-------------', 1)[0]\n",
    "df[\"has_other_content\"] = df[\"content\"].str.contains(\"-------------\")\n",
    "df[\"if_forwarded\"] = df[\"content\"].str.contains(\"------------- Forwarded\")\n",
    "df['content'] = df.content.map(split_other_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41be4ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['pre_info','test_true', 'num_info'], axis = 1).set_index(\"file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3aed539a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_emails = pd.DataFrame(columns=['message', 'is_phishing'])\n",
    "ham_emails['message'] = df['content']\n",
    "ham_emails['is_phishing'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6a6ead40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>is_phishing</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/Users/atacank/Downloads/maildir/arnold-j/notes_inbox/36.</th>\n",
       "      <td>John: ? I'm not really sure what happened betw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/atacank/Downloads/maildir/arnold-j/notes_inbox/19.</th>\n",
       "      <td>i suck-hope youve made more money in natgas la...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/atacank/Downloads/maildir/arnold-j/notes_inbox/50.</th>\n",
       "      <td>Hi,     Following the e-mail you have receive...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/atacank/Downloads/maildir/arnold-j/notes_inbox/3.</th>\n",
       "      <td>Conference Room TBD.    This meeting will be t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/atacank/Downloads/maildir/arnold-j/notes_inbox/9.</th>\n",
       "      <td>Mike- I have their trader coming into the offi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/atacank/Downloads/maildir/lavorato-j/personal/75.</th>\n",
       "      <td>John,  Happy New Year!!  I wish you and your f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/atacank/Downloads/maildir/lavorato-j/personal/165.</th>\n",
       "      <td>Thanks Andy for pulling this together!  Hi eve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/atacank/Downloads/maildir/lavorato-j/personal/35.</th>\n",
       "      <td>Here it is.  Good luck.   --anthony         \\t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/atacank/Downloads/maildir/lavorato-j/personal/10.</th>\n",
       "      <td>Hi John, Here is a detailed summary of all the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/atacank/Downloads/maildir/lavorato-j/personal/76.</th>\n",
       "      <td>John -- Sorry we did not catch up when I was ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              message  \\\n",
       "file                                                                                                    \n",
       "/Users/atacank/Downloads/maildir/arnold-j/notes...  John: ? I'm not really sure what happened betw...   \n",
       "/Users/atacank/Downloads/maildir/arnold-j/notes...  i suck-hope youve made more money in natgas la...   \n",
       "/Users/atacank/Downloads/maildir/arnold-j/notes...   Hi,     Following the e-mail you have receive...   \n",
       "/Users/atacank/Downloads/maildir/arnold-j/notes...  Conference Room TBD.    This meeting will be t...   \n",
       "/Users/atacank/Downloads/maildir/arnold-j/notes...  Mike- I have their trader coming into the offi...   \n",
       "...                                                                                               ...   \n",
       "/Users/atacank/Downloads/maildir/lavorato-j/per...  John,  Happy New Year!!  I wish you and your f...   \n",
       "/Users/atacank/Downloads/maildir/lavorato-j/per...  Thanks Andy for pulling this together!  Hi eve...   \n",
       "/Users/atacank/Downloads/maildir/lavorato-j/per...  Here it is.  Good luck.   --anthony         \\t...   \n",
       "/Users/atacank/Downloads/maildir/lavorato-j/per...  Hi John, Here is a detailed summary of all the...   \n",
       "/Users/atacank/Downloads/maildir/lavorato-j/per...   John -- Sorry we did not catch up when I was ...   \n",
       "\n",
       "                                                    is_phishing  \n",
       "file                                                             \n",
       "/Users/atacank/Downloads/maildir/arnold-j/notes...            0  \n",
       "/Users/atacank/Downloads/maildir/arnold-j/notes...            0  \n",
       "/Users/atacank/Downloads/maildir/arnold-j/notes...            0  \n",
       "/Users/atacank/Downloads/maildir/arnold-j/notes...            0  \n",
       "/Users/atacank/Downloads/maildir/arnold-j/notes...            0  \n",
       "...                                                         ...  \n",
       "/Users/atacank/Downloads/maildir/lavorato-j/per...            0  \n",
       "/Users/atacank/Downloads/maildir/lavorato-j/per...            0  \n",
       "/Users/atacank/Downloads/maildir/lavorato-j/per...            0  \n",
       "/Users/atacank/Downloads/maildir/lavorato-j/per...            0  \n",
       "/Users/atacank/Downloads/maildir/lavorato-j/per...            0  \n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_emails"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
